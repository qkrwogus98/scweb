#!/usr/bin/env python3
"""
CICLONE backup.sql PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ (.env ì§€ì›)
.env íŒŒì¼ì˜ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •ì„ ìë™ìœ¼ë¡œ ì½ì–´ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import os
import sys
import subprocess
import psycopg2
from psycopg2 import sql
import argparse
import logging
from datetime import datetime
from pathlib import Path

# python-dotenv íŒ¨í‚¤ì§€ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìˆ˜ë™ íŒŒì‹±
try:
    from dotenv import load_dotenv
    DOTENV_AVAILABLE = True
except ImportError:
    DOTENV_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class EnvConfigLoader:
    """í™˜ê²½ë³€ìˆ˜ ë° .env íŒŒì¼ ì„¤ì • ë¡œë”"""
    
    def __init__(self, env_file='.env'):
        self.env_file = env_file
        self.config = {}
        
    def load_env_file_manual(self):
        """ìˆ˜ë™ìœ¼ë¡œ .env íŒŒì¼ íŒŒì‹±"""
        if not os.path.exists(self.env_file):
            logger.warning(f".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.env_file}")
            return
            
        with open(self.env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    # ë”°ì˜´í‘œ ì œê±°
                    value = value.strip('\'"')
                    os.environ[key] = value
                    
        logger.info(f".env íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {self.env_file}")
    
    def load_config(self):
        """í™˜ê²½ë³€ìˆ˜ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë¡œë“œ"""
        if DOTENV_AVAILABLE:
            load_dotenv(self.env_file)
            logger.info("python-dotenvë¥¼ ì‚¬ìš©í•˜ì—¬ .env íŒŒì¼ ë¡œë“œ")
        else:
            logger.info("python-dotenvê°€ ì—†ì–´ì„œ ìˆ˜ë™ìœ¼ë¡œ .env íŒŒì¼ íŒŒì‹±")
            self.load_env_file_manual()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì¶”ì¶œ
        self.config = {
            'host': os.getenv('DB_POSTGRES_HOST', 'localhost'),
            'port': int(os.getenv('DB_POSTGRES_PORT', 5432)),
            'database': os.getenv('DB_POSTGRES_NAME', 'appdb'),
            'user': os.getenv('DB_POSTGRES_USERNAME', 'postgres'),
            'password': os.getenv('DB_POSTGRES_PASSWORD', ''),
            'schema': os.getenv('DB_POSTGRES_SCHEMA', 'postgresql')
        }
        
        # ì¶”ê°€ ì„¤ì •ë“¤
        self.config.update({
            'sms_id': os.getenv('SMS_ID'),
            'sms_key': os.getenv('SMS_KEY'),
            'cesium_token': os.getenv('CESIUM_TOKEN')
        })
        
        logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë¡œë“œ: {self.config['user']}@{self.config['host']}:{self.config['port']}/{self.config['database']}")
        return self.config

class CicloneMigrator:
    def __init__(self, source_file, config, target_db_name=None):
        self.source_file = source_file
        self.config = config
        self.target_db_name = target_db_name or config['database']
        self.connection = None
        
    def connect_to_target_db(self):
        """ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°"""
        try:
            self.connection = psycopg2.connect(
                host=self.config['host'],
                port=self.config['port'],
                database=self.target_db_name,
                user=self.config['user'],
                password=self.config['password']
            )
            logger.info(f"ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²° ì„±ê³µ: {self.config['host']}:{self.config['port']}/{self.target_db_name}")
            return True
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def check_backup_file(self):
        """ë°±ì—… íŒŒì¼ ì¡´ì¬ ë° ìœ íš¨ì„± ê²€ì‚¬"""
        if not os.path.exists(self.source_file):
            logger.error(f"ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.source_file}")
            return False
            
        file_size = os.path.getsize(self.source_file)
        logger.info(f"ë°±ì—… íŒŒì¼ í¬ê¸°: {file_size / 1024 / 1024:.2f} MB")
            
        # íŒŒì¼ ë‚´ìš© ê°„ë‹¨ ê²€ì‚¬
        with open(self.source_file, 'r', encoding='utf-8', errors='ignore') as f:
            first_lines = f.read(1000)
            if 'PostgreSQL' in first_lines or 'CREATE TABLE' in first_lines:
                logger.info("PostgreSQL ë°±ì—… íŒŒì¼ í˜•ì‹ í™•ì¸")
            else:
                logger.warning("PostgreSQL ë°±ì—… íŒŒì¼ í˜•ì‹ì´ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
        return True
    
    def create_target_database(self):
        """ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±"""
        try:
            # postgres ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•˜ì—¬ ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            temp_conn = psycopg2.connect(
                host=self.config['host'],
                port=self.config['port'],
                database='postgres',  # ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°
                user=self.config['user'],
                password=self.config['password']
            )
            temp_conn.autocommit = True
            cursor = temp_conn.cursor()
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì¡´ì¬ í™•ì¸
            cursor.execute("SELECT 1 FROM pg_catalog.pg_database WHERE datname = %s", 
                          (self.target_db_name,))
            exists = cursor.fetchone()
            
            if not exists:
                cursor.execute(sql.SQL("CREATE DATABASE {} WITH ENCODING 'UTF8'").format(
                    sql.Identifier(self.target_db_name)
                ))
                logger.info(f"ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±: {self.target_db_name}")
            else:
                logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {self.target_db_name}")
            
            cursor.close()
            temp_conn.close()
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def backup_existing_data(self):
        """ê¸°ì¡´ ë°ì´í„° ë°±ì—…"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_filename = f"backup_{self.target_db_name}_{timestamp}.sql"
            
            cmd = [
                'pg_dump',
                '-h', self.config['host'],
                '-p', str(self.config['port']),
                '-U', self.config['user'],
                '-d', self.target_db_name,
                '-f', backup_filename,
                '--no-password',
                '--verbose'
            ]
            
            env = os.environ.copy()
            env['PGPASSWORD'] = self.config['password']
            
            logger.info(f"ê¸°ì¡´ ë°ì´í„° ë°±ì—… ì‹œì‘: {backup_filename}")
            result = subprocess.run(cmd, env=env, capture_output=True, text=True)
            
            if result.returncode == 0:
                backup_size = os.path.getsize(backup_filename) / 1024 / 1024
                logger.info(f"ê¸°ì¡´ ë°ì´í„° ë°±ì—… ì™„ë£Œ: {backup_filename} ({backup_size:.2f} MB)")
                return backup_filename
            else:
                logger.warning(f"ê¸°ì¡´ ë°ì´í„° ë°±ì—… ì‹¤íŒ¨: {result.stderr}")
                return None
                
        except Exception as e:
            logger.warning(f"ê¸°ì¡´ ë°ì´í„° ë°±ì—… ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def get_ciclone_tables(self):
        """CICLONE í”„ë¡œì íŠ¸ì˜ í…Œì´ë¸” ëª©ë¡ ë°˜í™˜"""
        return [
            'device', 'logs', 'model', 'position', 
            'sensor', 'simulation', 'station', 'user'
        ]
    
    def clear_existing_tables(self):
        """ê¸°ì¡´ CICLONE í…Œì´ë¸”ë“¤ ì •ë¦¬"""
        try:
            cursor = self.connection.cursor()
            tables = self.get_ciclone_tables()
            
            # ì™¸ë˜í‚¤ ì œì•½ ì¡°ê±´ì„ ë¬´ì‹œí•˜ê³  í…Œì´ë¸” ì‚­ì œ
            cursor.execute('SET session_replication_role = replica;')
            
            for table in tables:
                cursor.execute(f'DROP TABLE IF EXISTS "{table}" CASCADE;')
                logger.info(f"í…Œì´ë¸” ì‚­ì œ: {table}")
            
            # ì‹œí€€ìŠ¤ë“¤ë„ ì‚­ì œ
            sequences = ['user_user_id_seq']
            for seq in sequences:
                cursor.execute(f'DROP SEQUENCE IF EXISTS {seq} CASCADE;')
                logger.info(f"ì‹œí€€ìŠ¤ ì‚­ì œ: {seq}")
            
            cursor.execute('SET session_replication_role = DEFAULT;')
            self.connection.commit()
            cursor.close()
            logger.info("ê¸°ì¡´ CICLONE í…Œì´ë¸” ì •ë¦¬ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ì •ë¦¬ ì‹¤íŒ¨: {e}")
            self.connection.rollback()
            return False
    
    def restore_backup(self):
        """ë°±ì—… íŒŒì¼ì„ ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ì— ë³µì›"""
        try:
            cmd = [
                'psql',
                '-h', self.config['host'],
                '-p', str(self.config['port']),
                '-U', self.config['user'],
                '-d', self.target_db_name,
                '-f', self.source_file,
                '--no-password',
                '--quiet'
            ]
            
            env = os.environ.copy()
            env['PGPASSWORD'] = self.config['password']
            
            logger.info("ë°±ì—… íŒŒì¼ ë³µì› ì‹œì‘...")
            result = subprocess.run(cmd, env=env, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info("ë°±ì—… íŒŒì¼ ë³µì› ì™„ë£Œ")
                return True
            else:
                logger.error(f"ë°±ì—… ë³µì› ì‹¤íŒ¨:")
                logger.error(result.stderr)
                # ì¼ë¶€ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•  ìˆ˜ ìˆëŠ” ê²½ìš°ê°€ ìˆìŒ
                if "already exists" in result.stderr or "duplicate key" in result.stderr:
                    logger.warning("ì¼ë¶€ ì¤‘ë³µ ì˜¤ë¥˜ê°€ ìˆì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                    return True
                return False
                
        except Exception as e:
            logger.error(f"ë°±ì—… ë³µì› ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def verify_migration(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦"""
        try:
            cursor = self.connection.cursor()
            tables = self.get_ciclone_tables()
            total_records = 0
            
            logger.info("=== ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ê²°ê³¼ ===")
            
            for table in tables:
                # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
                cursor.execute("""
                    SELECT COUNT(*) FROM information_schema.tables 
                    WHERE table_name = %s AND table_schema = 'public'
                """, (table,))
                
                if cursor.fetchone()[0] == 0:
                    logger.warning(f"âŒ í…Œì´ë¸”ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {table}")
                else:
                    # ë ˆì½”ë“œ ìˆ˜ í™•ì¸
                    cursor.execute(f'SELECT COUNT(*) FROM "{table}"')
                    count = cursor.fetchone()[0]
                    total_records += count
                    logger.info(f"âœ… í…Œì´ë¸” {table}: {count:,}ê°œ ë ˆì½”ë“œ")
            
            logger.info(f"ì´ {total_records:,}ê°œ ë ˆì½”ë“œê°€ ë§ˆì´ê·¸ë ˆì´ì…˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
            cursor.close()
            return True
            
        except Exception as e:
            logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def migrate(self, create_db=True, backup_existing=True, clear_tables=False):
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info("=" * 50)
        logger.info("CICLONE backup.sql ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        logger.info(f"ì†ŒìŠ¤ íŒŒì¼: {self.source_file}")
        logger.info(f"ëŒ€ìƒ DB: {self.config['host']}:{self.config['port']}/{self.target_db_name}")
        logger.info("=" * 50)
        
        # 1. ë°±ì—… íŒŒì¼ í™•ì¸
        if not self.check_backup_file():
            return False
        
        # 2. ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (í•„ìš”ì‹œ)
        if create_db and not self.create_target_database():
            return False
        
        # 3. ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        if not self.connect_to_target_db():
            return False
        
        try:
            # 4. ê¸°ì¡´ ë°ì´í„° ë°±ì—… (ê¶Œì¥)
            backup_file = None
            if backup_existing:
                backup_file = self.backup_existing_data()
            
            # 5. ê¸°ì¡´ í…Œì´ë¸” ì •ë¦¬ (ì˜µì…˜)
            if clear_tables:
                if not self.clear_existing_tables():
                    logger.warning("í…Œì´ë¸” ì •ë¦¬ ì‹¤íŒ¨, ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # 6. ë°±ì—… íŒŒì¼ ë³µì›
            if not self.restore_backup():
                logger.error("ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨")
                return False
            
            # 7. ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦
            self.verify_migration()
            
            logger.info("=" * 50)
            logger.info("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
            if backup_file:
                logger.info(f"ğŸ“ ê¸°ì¡´ ë°ì´í„° ë°±ì—…: {backup_file}")
            logger.info("=" * 50)
            return True
            
        finally:
            if self.connection:
                self.connection.close()

def main():
    parser = argparse.ArgumentParser(description='CICLONE backup.sql ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬ (.env ì§€ì›)')
    parser.add_argument('backup_file', nargs='?', default='backup.sql', 
                       help='ë°±ì—… SQL íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: backup.sql)')
    parser.add_argument('--env-file', default='.env', help='.env íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--target-db', help='ëŒ€ìƒ ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ê¸°ë³¸ê°’: .envì˜ DB_POSTGRES_NAME)')
    parser.add_argument('--create-db', action='store_true', help='ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±')
    parser.add_argument('--no-backup', action='store_true', help='ê¸°ì¡´ ë°ì´í„° ë°±ì—…í•˜ì§€ ì•ŠìŒ')
    parser.add_argument('--clear-tables', action='store_true', help='ê¸°ì¡´ CICLONE í…Œì´ë¸” ì‚­ì œ')
    
    args = parser.parse_args()
    
    # í™˜ê²½ë³€ìˆ˜ ì„¤ì • ë¡œë“œ
    config_loader = EnvConfigLoader(args.env_file)
    config = config_loader.load_config()
    
    if not config['password']:
        logger.error("ë°ì´í„°ë² ì´ìŠ¤ ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # ë§ˆì´ê·¸ë ˆì´í„° ìƒì„± ë° ì‹¤í–‰
    migrator = CicloneMigrator(
        args.backup_file, 
        config, 
        args.target_db or config['database']
    )
    
    success = migrator.migrate(
        create_db=args.create_db,
        backup_existing=not args.no_backup,
        clear_tables=args.clear_tables
    )
    
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()